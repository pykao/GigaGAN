# Evaluating GigaGAN using clean-FID

We employ the Fre'chet Inception Distance (FID) and CLIP-score to compare diverse generative models. We use a clean-FID library to ensure that the FID is calculated without any problems of aliasing. Moreover, we have released our evaluation code and pre-computed images in this repository.

# Requirements 

Before starting, make sure to install PyTorch 1.7.1 (or a newer version) and torchvision along with some additional dependencies. 

```
$ conda create -n GigaGAN python=3.9
$ conda activate GigaGAN 
$ conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia
$ pip install ftfy regex tqdm
$ pip install git+https://github.com/openai/CLIP.git
$ pip install open_clip_torch clean-fid
$ pip install Cython
$ pip install git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI
```

# Image Download

We offer pre-calculated images that are generated by the GigaGAN generators. All the images are saved in the .png format. Users can download and assess the images using the provided scripts.

In the case of ImageNet real images, users must download the images themselves. Make sure that your ImageNet has the following file structure.

```
data
└── ImageNet
    ├── train
    │   ├── cls0
    │   │   ├── train0.png
    │   │   ├── train1.png
    │   │   └── ...
    │   ├── cls1
    │   └── ...
    └── valid
        ├── cls0
        │   ├── valid0.png
        │   ├── valid1.png
        │   └── ...
        ├── cls1
        └── ...
```

Below are the links to download the pre-generated images:

[GigaGAN_cond_imagenet256](https://drive.google.com/file/d/1vAuTUfkeRX045AMhUPcguxwov2dqAVtJ/view?usp=share_link)

[GigaGAN_uncond_imagenet64to256](https://drive.google.com/file/d/1aDeCFCLzWW52L28yE7qYdUXEPSKZnvKD/view?usp=share_link)

[GigaGAN_t2i_coco256](https://drive.google.com/file/d/1sg180IaL9MS4yAxv8P8e7yqfgSVuUtUF/view?usp=share_link)

[GigaGAN_t2i_coco256_diff_noised](https://drive.google.com/file/d/1KbuGev6X26naSrEGHH6Mb40EBXvuaoaF/view?usp=share_link) (Strong diffusion noises were added before upsampling)

[GigaGAN_cond_upsampler_laion128to1024](https://drive.google.com/file/d/1FFfoYxWVLw0TKwcmeYc_uD_pj4tR5Wrv/view?usp=share_link)

# Evaluation scripts

Users can evaluate the GigaGAN models by executing the following commands:

```bash
# class-conditional image generation on ImageNet (noise-to-256px)
bash scripts/evaluate_GigaGAN_cond_imagenet256.sh
```

```bash
# unconditional image super-resolution on ImageNet (64px-to-256px)
bash scripts/evaluate_GigaGAN_uncond_imagenet64to256.sh
```

```bash
# text-conditional image generation on COCO2014 validation dataset (noise-to-256px) without adding diffusion noises
bash scripts/evaluate_GigaGAN_t2i_coco256.sh
```

```bash
# text-conditional image generation on COCO2014 validation dataset (noise-to-256px) with adding diffusion noises 
bash scripts/evaluate_GigaGAN_t2i_coco256_diff_noised.sh
```

```bash
# text-conditional image super-resolution on laion dataset (128px-to-1024px)
bash scripts/evaluate_GigaGAN_cond_upsampler_laion128to1024.sh
```

# Evaluation Results

| Paper/Reproduced | ImageNet-Noise-to-256px | ImageNet-64px-to-256px | COCO-Noise-to-256px | COCO-Noise-to-256px-diff-noised | LAION-128px-to-1024px |
|------------------|:-----------------------:|:----------------------:|:-------------------:|:-------------------------------:|:---------------------:|
| FID              |        3.45/ 3.53        |         1.2/1.2        |      9.09/9.06       |       - /12.16       |       1.54/1.54       |
| CLIP score       |            -            |            -           |     - /0.33      |       - /0.32     |           -           |


Please note that the results mentioned above were computed using the clean-FID library. The difference in FID scores (3.45 vs. 3.53) for ImageNet-Noise-to-256px images attributes to the evaluation library used. In order to make a fair comparison of GigaGAN with other state-of-the-art generative models like StyleGAN-XL, ADM-G, and RQ-Transformer, we adopted StudioGAN's evaluation protocol for the Table A1 in our paper, which yielded a FID score of 3.45.

The FID of ImageNet-Noise-to-256px reported in the paper was obtained using the following command. For further information, please refer to the [StudioGAN library](https://github.com/POSTECH-CVLab/PyTorch-StudioGAN).

```
CUDA_VISIBLE_DEVICES=0 python3 src/evaluate.py -metrics fid --dset1_moments "/PATH_TO_MOMENT/ImageNet_256_lanczos_train_friendly_InceptionV3_tf_moments.npz" --dset2 "/PATH_TO_FAKE_IMAGES/GigaGAN_cond_imagenet256/fake_images/" --post_resizer "friendly"
```

# References

```
@inproceedings{kang2023gigagan,
  author    = {Kang, Minguk and Zhu, Jun-Yan and Zhang, Richard and Park, Jaesik and Shechtman, Eli and Paris, Sylvain and Park, Taesung},
  title     = {Scaling up GANs for Text-to-Image Synthesis},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2023},
}
```

```
@inproceedings{parmar2021cleanfid,
  title={On Aliased Resizing and Surprising Subtleties in GAN Evaluation},
  author={Parmar, Gaurav and Zhang, Richard and Zhu, Jun-Yan},
  booktitle={CVPR},
  year={2022}
}
```
